{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58799b03-5168-4a6e-a989-140c5de8db7a",
   "metadata": {},
   "source": [
    "# Combine History Files along the Time Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14e56d9-de4c-4b5c-b1a2-7e39c09a078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "import numpy as np\n",
    "\n",
    "#from rechunker import rechunk\n",
    "\n",
    "import dask.distributed\n",
    "from dask.distributed import Client\n",
    "from ncar_jobqueue import NCARCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb96fee-91df-4685-88e5-29becb8454c7",
   "metadata": {},
   "source": [
    "### Configuration/Tuning Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9290b1cd-4b98-4185-8269-3f184321d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final target folder\n",
    "TARGET_FOLDER = '/glade/scratch/bonnland/DART/ds345.0/atm_zarr/'\n",
    "\n",
    "# Target folder for performance tuning\n",
    "#TARGET_FOLDER = '/glade/scratch/bonnland/DART/ds345.0/ZARR-SCRATCH/'\n",
    "\n",
    "# TARGET_CHUNKS = {'lat': 32, \n",
    "#                  'slat': 32, \n",
    "#                  'lon': 32, \n",
    "#                  'slon': 32, \n",
    "#                  'lev': -1,\n",
    "#                  'time': 30}\n",
    "TARGET_CHUNKS = {'lat': 32, \n",
    "                 'slat': 32, \n",
    "                 'lon': 32, \n",
    "                 'slon': 32, \n",
    "                 'lev': 8,\n",
    "                 'time': 80}\n",
    "\n",
    "INPUT_FOLDER = '/glade/scratch/bonnland/DART/ds345.0/atm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccf743d-3737-471f-ae32-4c810e95d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x2aac16429f40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to keep metadata during Xarray operations.\n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6504c00-ed72-4b73-a21a-8f3a257f8194",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run These Cells for Dask Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e71ad93-5102-49c2-b799-ac947db37201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c3ebb1272a4fd88004c9a5efb6f905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='\\n            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-Ouâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask\n",
    "from ncar_jobqueue import NCARCluster\n",
    "\n",
    "# Processes is processes PER CORE.\n",
    "# This one works fine.\n",
    "#cluster = NCARCluster(cores=15, processes=1, memory='100GB', project='STDD0003')\n",
    "# This one also works, but occasionally hangs near the end.\n",
    "#cluster = NCARCluster(cores=10, processes=1, memory='50GB', project='STDD0003')\n",
    "\n",
    "# For Cheyenne\n",
    "\n",
    "# I've run 10 workers on each node and eventually gotten RAM shortages and Dask crashes.\n",
    "#num_cores = 10   # This pushes memory to 55% or so\n",
    "num_cores = 16\n",
    "num_processes=8\n",
    "memory = '109GB'\n",
    "walltime = \"1:30:00\" #\"0:30:00\" \n",
    "\n",
    "# For this dataset, each python worker needs >= 5GB RAM to avoid disk spills/freezes.\n",
    "\n",
    "cluster = NCARCluster(cores=num_cores, processes=num_processes, memory=memory, walltime=walltime)\n",
    "num_nodes = 3\n",
    "\n",
    "cluster.scale(jobs=num_nodes)\n",
    "\n",
    "from distributed import Client\n",
    "from distributed.utils import format_bytes\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ee1ce-e282-4b65-889b-c467132f8a38",
   "metadata": {},
   "source": [
    "### Assign new time coordinates before concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b8e661-17dc-4257-9a3c-6408ceb16ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    \"\"\"This function gets called on each original dataset before concatenation.\n",
    "       Convert the time value from index to datetime64.  \n",
    "    \"\"\"\n",
    "\n",
    "    date_string = str(ds['date'].values[0])\n",
    "    \n",
    "    seconds = ds['datesec'].values[0]\n",
    "    hour_string = str(int(seconds/3600))\n",
    "    hour_string = hour_string.zfill(2)\n",
    "    \n",
    "    new_date = pd.to_datetime(f'{date_string} {hour_string}', format='%Y%m%d %H')\n",
    "    ds_fixed = ds.assign_coords(time=[new_date])\n",
    "    \n",
    "    return ds_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0451b-66bb-4af8-887b-4a6af4651a4e",
   "metadata": {},
   "source": [
    "## Create a Zarr Store for each of 80 ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e64df0-2f6f-4fae-8e48-b25463e8d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(member_id):\n",
    "    \"\"\"Returns a list of NetCDF files for an ensemble member.\n",
    "    \"\"\"\n",
    "    padded_id = str(member_id).zfill(4)\n",
    "    data_filter = f'{INPUT_FOLDER}/*.cam_{padded_id}*.nc'\n",
    "\n",
    "    file_list = fs.glob(data_filter)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2e3627-70ad-446e-bd8a-5e2e35794d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(member_id):\n",
    "    \"\"\"Given an integer id for some ensemble member, return a Xarray dataset\n",
    "       created from its history files.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_list = get_file_list(member_id)\n",
    "\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "        ds = xr.open_mfdataset(file_list, concat_dim='time', parallel=True,\n",
    "                               preprocess=preprocess, \n",
    "                               data_vars='minimal', coords='minimal', compat='override')\n",
    "\n",
    "    # Rechunk after combining time steps, so we can chunk time.\n",
    "    # Note that \"chunks\" specifies the number of elements *in* each chunk,\n",
    "    # not the number of chunks.\n",
    "    ds = ds.chunk(chunks=TARGET_CHUNKS)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2d02b2-062e-4052-a9b5-944d6e35a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(ds, member_id):\n",
    "    save_folder = TARGET_FOLDER\n",
    "    store = f'{save_folder}/member_{member_id}.zarr'\n",
    "    try:\n",
    "        ds.to_zarr(store, consolidated=True)\n",
    "        del ds\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write {store}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623656e-5e7c-4842-a3f9-3dae5b5cee1f",
   "metadata": {},
   "source": [
    "### Loop over ensemble members and create a Zarr store for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed22692b-cffd-4c6f-a8c7-2999361dc9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating store for member 11 ...\n",
      "  Creating store for member 12 ...\n",
      "  Creating store for member 13 ...\n",
      "  Creating store for member 14 ...\n",
      "  Creating store for member 15 ...\n",
      "  Creating store for member 16 ...\n",
      "  Creating store for member 17 ...\n",
      "  Creating store for member 18 ...\n",
      "  Creating store for member 19 ...\n",
      "  Creating store for member 20 ...\n",
      "  Creating store for member 21 ...\n",
      "  Creating store for member 22 ...\n",
      "  Creating store for member 23 ...\n",
      "  Creating store for member 24 ...\n",
      "  Creating store for member 25 ...\n",
      "  Creating store for member 26 ...\n",
      "  Creating store for member 27 ...\n",
      "  Creating store for member 28 ...\n",
      "  Creating store for member 29 ...\n",
      "  Creating store for member 30 ...\n",
      "  Creating store for member 31 ...\n",
      "  Creating store for member 32 ...\n",
      "  Creating store for member 33 ...\n",
      "  Creating store for member 34 ...\n",
      "  Creating store for member 35 ...\n",
      "  Creating store for member 36 ...\n",
      "  Creating store for member 37 ...\n",
      "  Creating store for member 38 ...\n",
      "  Creating store for member 39 ...\n",
      "  Creating store for member 40 ...\n",
      "  Creating store for member 41 ...\n",
      "  Creating store for member 42 ...\n",
      "  Creating store for member 43 ...\n",
      "  Creating store for member 44 ...\n",
      "  Creating store for member 45 ...\n",
      "  Creating store for member 46 ...\n",
      "  Creating store for member 47 ...\n",
      "  Creating store for member 48 ...\n",
      "  Creating store for member 49 ...\n",
      "  Creating store for member 50 ...\n",
      "  Creating store for member 51 ...\n",
      "  Creating store for member 52 ...\n",
      "  Creating store for member 53 ...\n",
      "  Creating store for member 54 ...\n",
      "  Creating store for member 55 ...\n",
      "  Creating store for member 56 ...\n",
      "  Creating store for member 57 ...\n",
      "  Creating store for member 58 ...\n",
      "  Creating store for member 59 ...\n",
      "  Creating store for member 60 ...\n",
      "  Creating store for member 61 ...\n",
      "  Creating store for member 62 ...\n",
      "  Creating store for member 63 ...\n",
      "  Creating store for member 64 ...\n",
      "  Creating store for member 65 ...\n",
      "  Creating store for member 66 ...\n",
      "  Creating store for member 67 ...\n",
      "  Creating store for member 68 ...\n",
      "  Creating store for member 69 ...\n",
      "  Creating store for member 70 ...\n",
      "  Creating store for member 71 ...\n",
      "  Creating store for member 72 ...\n",
      "  Creating store for member 73 ...\n",
      "  Creating store for member 74 ...\n",
      "  Creating store for member 75 ...\n",
      "  Creating store for member 76 ...\n",
      "  Creating store for member 77 ...\n",
      "  Creating store for member 78 ...\n",
      "  Creating store for member 79 ...\n",
      "  Creating store for member 80 ...\n",
      "CPU times: user 40min 48s, sys: 1min 34s, total: 42min 23s\n",
      "Wall time: 47min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fs = fsspec.filesystem(None)\n",
    "\n",
    "#for i in range(1):\n",
    "#for i in range(10):\n",
    "for i in np.arange(10, 80):\n",
    "    member_id = i+1\n",
    "    print(f'  Creating store for member {member_id} ...')\n",
    "    ds = get_dataset(member_id)\n",
    "    save_data(ds, member_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f087de4f-87fc-47b0-9a6f-1a098a7ccfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 19 12:22:19 MDT 2021\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff16d1d-a833-4caa-a54f-f2a1eca0d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "/glade/work/bonnland/miniconda3/envs/lens-conversion/lib/python3.8/site-packages/dask_jobqueue/core.py:360: FutureWarning: ignoring was deprecated in version 2021.06.1 and will be removed in a future release. Please use contextlib.suppress from the standard library instead.\n",
      "  with ignoring(RuntimeError):  # deleting job when job already gone\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe295e91-6f60-47a0-b865-38bcfbf9af62",
   "metadata": {},
   "source": [
    "### Verify details from one of the created stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021d8dc-9343-419f-9669-59f5c062c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = '/glade/scratch/bonnland/DART/ds345.0/atm_zarr/member_22.zarr'\n",
    "ds = xr.open_zarr(store, consolidated=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c36b9f-ed05-40c6-b84b-79b2c14f302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1429ae-0086-4dbb-a428-748a2a8bb78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8981f-8f1b-4a0e-a6f4-1f9ae8516938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9ff0e-91bc-409a-860b-5a8fb934943e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7feae00-7400-4978-bbed-6a5f2770dbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df99ff-6e02-4bf0-b700-0c774b9de597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379dfaf-7776-43ef-a1fc-fa16d03cba3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b7b33-3a0a-43cb-8a2d-1d8c3f40a139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
