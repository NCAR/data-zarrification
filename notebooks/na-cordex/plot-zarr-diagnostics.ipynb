{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Diagnostic Plots for NA-CORDEX Zarr Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run These Cells for Dask Processing (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "# This line makes the dashboard link work on JupyterHub.\n",
    "dask.config.set({'distributed.dashboard.link': '/proxy/{port}/status'})\n",
    "\n",
    "num_jobs = 35\n",
    "walltime = '6:00:00'\n",
    "\n",
    "cluster = PBSCluster(cores=1, processes=1, walltime=walltime, queue='casper', \n",
    "                     resource_spec='select=1:ncpus=1:mem=10GB',)\n",
    "cluster.scale(jobs=num_jobs)\n",
    "\n",
    "\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hide unused subplot panels (Helper Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_subplots(axes, start_row):\n",
    "    '''Given an array of axes and a row index, hide plots with this row index or later.\n",
    "    Subplot array can be 1-D or 2-D.\n",
    "    '''\n",
    "    subplot_ndims = axes.ndim\n",
    "    if subplot_ndims == 1:\n",
    "        nrows = len(axes)\n",
    "        for row in np.arange(start_row, nrows):\n",
    "            axes[row].axis('off')\n",
    "    else:\n",
    "        assert(subplot_ndims == 2)\n",
    "        (nrows, ncols) = axes.shape\n",
    "        for row in np.arange(start_row, nrows):\n",
    "            for col in np.arange(ncols):\n",
    "                axes[row][col].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Single Map Plot (Helper Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMap(ax, map_slice, date_object=None, member_id=None):\n",
    "    '''Create a map plot on the given axes, with min/max as text'''\n",
    "\n",
    "    ax.imshow(map_slice, origin='lower')\n",
    "\n",
    "    minval = map_slice.min(dim = ['lat', 'lon'])\n",
    "    maxval = map_slice.max(dim = ['lat', 'lon'])\n",
    "\n",
    "    # Format values to have at least 4 digits of precision.\n",
    "    ax.text(0.01, 0.03, \"%4g\" % minval, transform=ax.transAxes, fontsize=12)\n",
    "    ax.text(0.99, 0.03, \"%4g\" % maxval, transform=ax.transAxes, fontsize=12, horizontalalignment='right')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    if date_object:\n",
    "        ax.set_title(date_object.values.astype(str)[:10], fontsize=12)\n",
    "        \n",
    "    if member_id:\n",
    "        ax.set_ylabel(member_id, fontsize=12)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Statistical Map Plots Over Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stat_maps(ds, data_var, store_name, plotdir):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotsPerPage = 4\n",
    "    numPages = np.ceil(numEnsembleMembers / numPlotsPerPage).astype(int)\n",
    "    numPlotCols = 4\n",
    "\n",
    "    figWidth = 25 \n",
    "    figHeight = 12 #20\n",
    "\n",
    "    pp = PdfPages(f'{plotdir}/{store_name}_maps.pdf')\n",
    "\n",
    "    for pageNum in range(numPages):\n",
    "\n",
    "        memberStart = pageNum * numPlotsPerPage\n",
    "        memberEnd = np.min((memberStart + numPlotsPerPage, numEnsembleMembers))\n",
    "        plot_row_index = 0\n",
    "\n",
    "        # If this is the final page, target empty subplots for hiding.\n",
    "        removeBlankSubplots = (pageNum == numPages-1) and (numEnsembleMembers < memberStart + numPlotsPerPage)\n",
    "\n",
    "        # Plot the aggregate statistics across time.\n",
    "        fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight), constrained_layout=True)\n",
    "\n",
    "        for index in np.arange(memberStart, memberEnd):\n",
    "            mem_id = member_names[index]\n",
    "            data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "\n",
    "            # Persist the slice so it's read from disk only once.\n",
    "            # This is faster when data values are reused many times.\n",
    "            data_slice = data_slice.persist()\n",
    "\n",
    "            data_agg = data_slice.min(dim='time')\n",
    "            plotMap(axs[plot_row_index, 0], data_agg, member_id=mem_id)\n",
    "\n",
    "            data_agg = data_slice.max(dim='time')\n",
    "            plotMap(axs[plot_row_index, 1], data_agg)\n",
    "\n",
    "            data_agg = data_slice.mean(dim='time')\n",
    "            plotMap(axs[plot_row_index, 2], data_agg)\n",
    "\n",
    "            data_agg = data_slice.std(dim='time')\n",
    "            plotMap(axs[plot_row_index, 3], data_agg)\n",
    "\n",
    "            plot_row_index = plot_row_index + 1\n",
    "\n",
    "        axs[0, 0].set_title(f'min({data_var})', fontsize=15)\n",
    "        axs[0, 1].set_title(f'max({data_var})', fontsize=15)\n",
    "        axs[0, 2].set_title(f'mean({data_var})', fontsize=15)\n",
    "        axs[0, 3].set_title(f'std({data_var})', fontsize=15)\n",
    "\n",
    "        #plt.colorbar(pcm0, ax = axs[:, 0], location='bottom', shrink=0.9, pad=0.02)\n",
    "        #plt.colorbar(pcm1, ax = axs[:, 1], location='bottom', shrink=0.9, pad=0.02)\n",
    "        #plt.colorbar(pcm2, ax = axs[:, 2], location='bottom', shrink=0.9, pad=0.02)\n",
    "        #plt.colorbar(pcm3, ax = axs[:, 3], location='bottom', shrink=0.9, pad=0.02)\n",
    "\n",
    "        if removeBlankSubplots:\n",
    "            hide_subplots(axs, plot_row_index)\n",
    "\n",
    "        plt.suptitle(store_name, fontsize=20)\n",
    "        pp.savefig()\n",
    "        plt.close()\n",
    "\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time Series Plots over Multiple Pages\n",
    "These also mark the locations of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(ds, data_var, store_name, plotdir):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotsPerPage = 4\n",
    "    numPages = np.ceil(numEnsembleMembers / numPlotsPerPage).astype(int)\n",
    "    numPlotCols = 1\n",
    "\n",
    "    figWidth = 25 \n",
    "    figHeight = 20\n",
    "\n",
    "    linewidth = 0.5\n",
    "\n",
    "    pp = PdfPages(f'{plotdir}/{store_name}_ts.pdf')\n",
    "\n",
    "    for pageNum in range(numPages):\n",
    "\n",
    "        memberStart = pageNum * numPlotsPerPage\n",
    "        memberEnd = np.min((memberStart + numPlotsPerPage, numEnsembleMembers))\n",
    "        plot_row_index = 0\n",
    "        \n",
    "        # If this is the final page, target empty subplots for hiding.\n",
    "        removeBlankSubplots = (pageNum == numPages-1) and (numEnsembleMembers < memberStart + numPlotsPerPage)\n",
    "\n",
    "        # Plot the aggregate statistics across time.\n",
    "        fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight))\n",
    "        #fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight), sharey='col')\n",
    "\n",
    "        print(f'Shape of subplots object: {axs.shape}')\n",
    "        \n",
    "        \n",
    "        for index in np.arange(memberStart, memberEnd):\n",
    "            mem_id = member_names[index]\n",
    "            data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "            unit_string = ds[data_var].attrs['units']\n",
    "            \n",
    "            # Persist the slice so it's read from disk only once.\n",
    "            # This is faster when data values are reused many times.\n",
    "            data_slice = data_slice.persist()\n",
    "\n",
    "            min_vals = data_slice.min(dim = ['lat', 'lon'])\n",
    "            max_vals = data_slice.max(dim = ['lat', 'lon'])\n",
    "            mean_vals = data_slice.mean(dim = ['lat', 'lon'])\n",
    "            std_vals = data_slice.std(dim = ['lat', 'lon'])\n",
    "\n",
    "            nan_indexes = np.isnan(min_vals)\n",
    "            nan_times = ds.time[nan_indexes]\n",
    "\n",
    "            axs[plot_row_index].plot(ds.time, max_vals, linewidth=linewidth, label='max', color='red')\n",
    "            axs[plot_row_index].plot(ds.time, min_vals, linewidth=linewidth, label='min', color='blue')\n",
    "            axs[plot_row_index].plot(ds.time, mean_vals, linewidth=linewidth, label='mean', color='black')\n",
    "            axs[plot_row_index].fill_between(ds.time, (mean_vals - std_vals), (mean_vals + std_vals), color='grey', \n",
    "                         linewidth=0, label='std', alpha=0.5)\n",
    "            \n",
    "            ymin, ymax = axs[plot_row_index].get_ylim()\n",
    "            rug_y = ymin + 0.01*(ymax-ymin)\n",
    "            axs[plot_row_index].plot(nan_times, [rug_y]*len(nan_times), '|', color='m', label='missing')\n",
    "            axs[plot_row_index].set_title(mem_id, fontsize=20)\n",
    "            axs[plot_row_index].legend(loc='upper right')\n",
    "            axs[plot_row_index].set_ylabel(unit_string)\n",
    "\n",
    "            plot_row_index = plot_row_index + 1\n",
    "\n",
    "        plt.suptitle(store_name, fontsize=25)\n",
    "        plt.tight_layout(pad=10.2, w_pad=3.5, h_pad=3.5)\n",
    "        \n",
    "        if removeBlankSubplots:\n",
    "            hide_subplots(axs, plot_row_index)\n",
    "            \n",
    "        pp.savefig()\n",
    "        plt.close()\n",
    "    pp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Maps of First, Middle, Last Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidDateIndexes(member_slice):\n",
    "    '''Search for the first and last dates with finite values.'''\n",
    "    min_values = member_slice.min(dim = ['lat', 'lon'])\n",
    "    is_finite = np.isfinite(min_values)\n",
    "    finite_indexes = np.where(is_finite)\n",
    "    start_index = finite_indexes[0][0]\n",
    "    end_index = finite_indexes[0][-1]\n",
    "    #print(f'start ={start_index}, end={end_index}')\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "def plot_first_mid_last(ds, data_var, store_name, plotdir):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotsPerPage = 4\n",
    "    numPages = np.ceil(numEnsembleMembers / numPlotsPerPage).astype(int)\n",
    "    numPlotCols = 3\n",
    "\n",
    "    figWidth = 18 \n",
    "    figHeight = 12 #20\n",
    "\n",
    "    pp = PdfPages(f'{plotdir}/{store_name}_fml.pdf')\n",
    "\n",
    "    for pageNum in range(numPages):\n",
    "\n",
    "        memberStart = pageNum * numPlotsPerPage\n",
    "        memberEnd = np.min((memberStart + numPlotsPerPage, numEnsembleMembers))\n",
    "        plot_row_index = 0\n",
    "\n",
    "        # If this is the final page, target empty subplots for hiding.\n",
    "        removeBlankSubplots = (pageNum == numPages-1) and (numEnsembleMembers < memberStart + numPlotsPerPage)\n",
    "\n",
    "        # Plot the aggregate statistics across time.\n",
    "        fig, axs = plt.subplots(numPlotsPerPage, numPlotCols, figsize=(figWidth, figHeight), constrained_layout=True)\n",
    "\n",
    "        for index in np.arange(memberStart, memberEnd):\n",
    "            mem_id = member_names[index]\n",
    "            data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "            \n",
    "            # Persist the slice so it's read from disk only once.\n",
    "            # This is faster when data values are reused many times.\n",
    "            data_slice = data_slice.persist()\n",
    "\n",
    "            start_index, end_index = getValidDateIndexes(data_slice)\n",
    "            midDateIndex = np.floor(len(ds.time) / 2).astype(int)\n",
    "\n",
    "            startDate = ds.time[start_index]\n",
    "            first_step = data_slice.sel(time=startDate) \n",
    "            ax = axs[plot_row_index, 0]\n",
    "            plotMap(ax, first_step, startDate, mem_id)\n",
    "\n",
    "            midDate = ds.time[midDateIndex]\n",
    "            mid_step = data_slice.sel(time=midDate)   \n",
    "            ax = axs[plot_row_index, 1]\n",
    "            plotMap(ax, mid_step, midDate)\n",
    "\n",
    "            endDate = ds.time[end_index]\n",
    "            last_step = data_slice.sel(time=endDate)            \n",
    "            ax = axs[plot_row_index, 2]\n",
    "            plotMap(ax, last_step, endDate)\n",
    "            \n",
    "            plot_row_index = plot_row_index + 1\n",
    " \n",
    "        plt.suptitle(store_name, fontsize=20)\n",
    "\n",
    "        if removeBlankSubplots:\n",
    "            hide_subplots(axs, plot_row_index)\n",
    "            \n",
    "        pp.savefig()\n",
    "        plt.close()\n",
    "\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over Zarr Stores in Directory and Make Plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, make the Zarr output directory a global variable.\n",
    "#dirout = '/glade/scratch/bonnland/na-cordex/zarr-demo'\n",
    "#zarr_directory = '/glade/scratch/bonnland/na-cordex/zarr/'\n",
    "zarr_directory = '/glade/scratch/bonnland/na-cordex/zarr-publish/'\n",
    "plot_directory = '/glade/scratch/bonnland/na-cordex/zarr-plots/'\n",
    "\n",
    "p = Path(zarr_directory)\n",
    "stores = list(p.rglob(\"*.zarr\"))\n",
    "#stores = list(p.rglob(\"uas.rcp85.*.zarr\"))\n",
    "for store in stores:\n",
    "    print(f'Opening {store}...')\n",
    "    try:\n",
    "        ds = xr.open_zarr(store.as_posix(), consolidated=True)\n",
    "        print('\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    data_vars = [vname for vname in ds.data_vars]\n",
    "    data_var = data_vars[0]\n",
    "    store_name = store.as_posix().split('/')[-1]\n",
    "    \n",
    "    # Only produce plots that haven't been created already.  \n",
    "    plotdir = plot_directory + store_name\n",
    "    if not os.path.exists(plotdir):\n",
    "        os.makedirs(plotdir)\n",
    "    else:\n",
    "        # Plots exist; skip to the next case.\n",
    "        del ds\n",
    "        continue\n",
    "    \n",
    "    plot_stat_maps(ds, data_var, store_name, plotdir)\n",
    "    plot_first_mid_last(ds, data_var, store_name, plotdir)\n",
    "    plot_timeseries(ds, data_var, store_name, plotdir)\n",
    "    \n",
    "    # See if we can avoid memory leaks in the lab session\n",
    "    del ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function producing Super-Wide Time Series Plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_wide(ds, data_var, store_name):\n",
    "    # Generate super-wide plot of individual time series. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotRows = numEnsembleMembers\n",
    "    numPlotCols = 4\n",
    "\n",
    "    figWidth = 200 #100 \n",
    "    figHeight = 80\n",
    "\n",
    "    linestyle = 'k.'\n",
    "    linewidth = 0.5\n",
    "    markersize = 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(numPlotRows, numPlotCols, figsize=(figWidth,figHeight), sharey='col')\n",
    "\n",
    "    for index in range(numEnsembleMembers):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "\n",
    "        data_agg = data_slice.min(dim=['lat', 'lon'])\n",
    "        axs[index, 0].plot(ds.time, data_agg, linewidth=linewidth)\n",
    "        axs[index, 0].plot(ds.time, data_agg, linestyle, markersize=markersize)\n",
    "        axs[index, 0].set_ylabel(mem_id, fontsize=15)\n",
    "\n",
    "        data_agg = data_slice.max(dim=['lat', 'lon'])\n",
    "        axs[index, 1].plot(ds.time, data_agg, linewidth=linewidth)\n",
    "        axs[index, 1].plot(ds.time, data_agg, linestyle, markersize=markersize)\n",
    "        axs[index, 1].set_ylabel(mem_id, fontsize=15)\n",
    "\n",
    "        data_agg = data_slice.mean(dim=['lat', 'lon'])\n",
    "        axs[index, 2].plot(ds.time, data_agg, linewidth=linewidth)\n",
    "        axs[index, 2].plot(ds.time, data_agg, linestyle, markersize=markersize)\n",
    "        axs[index, 2].set_ylabel(mem_id, fontsize=15)\n",
    "\n",
    "        data_agg = data_slice.std(dim=['lat', 'lon'])\n",
    "        axs[index, 3].plot(ds.time, data_agg, linewidth=linewidth)\n",
    "        axs[index, 3].plot(ds.time, data_agg, linestyle, markersize=markersize)\n",
    "        axs[index, 3].set_ylabel(mem_id, fontsize=15)\n",
    "       \n",
    "    \n",
    "    axs[0, 0].set_title(f'min({var})', fontsize=40)\n",
    "    axs[0, 1].set_title(f'max({var})', fontsize=40)\n",
    "    axs[0, 2].set_title(f'mean({var})', fontsize=40)\n",
    "    axs[0, 3].set_title(f'std({var})', fontsize=40)\n",
    "    \n",
    "\n",
    "    plt.suptitle(store, fontsize=50)\n",
    "    plt.tight_layout(pad=20.2, w_pad=5.5, h_pad=5.5)\n",
    "    plt.savefig(f'{store_name}_ts.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Map Plots Over a SINGLE Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maps_OLD(ds, data_var, store_name):\n",
    "    # Generate plot. \n",
    "    #\n",
    "    # With 30 workers, expect 1 minute walltime for computation and 1-2 minutes for plot rendering.\n",
    "    #\n",
    "    member_names = ds.coords['member_id'].values\n",
    "    numEnsembleMembers = member_names.size\n",
    "\n",
    "    numPlotsPerPage = 4\n",
    "    numPages = np.ceil(numEnsembleMembers / numPlotsPerPage).astype(int)\n",
    "\n",
    "    numPlotRows = numEnsembleMembers\n",
    "    numPlotCols = 4\n",
    "\n",
    "    figWidth = 17 \n",
    "    figHeight = 35\n",
    "\n",
    "    fig, axs = plt.subplots(numPlotRows, numPlotCols, figsize=(figWidth,figHeight), constrained_layout=True)\n",
    "\n",
    "    for index in range(numEnsembleMembers):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "\n",
    "        data_agg = data_slice.min(dim='time')\n",
    "        pcm0 = axs[index, 0].imshow(data_agg, origin='lower')\n",
    "        axs[index, 0].set_ylabel(mem_id, fontsize=8)\n",
    "\n",
    "        data_agg = data_slice.max(dim='time')\n",
    "        pcm1 = axs[index, 1].imshow(data_agg, origin='lower')\n",
    "        axs[index, 1].set_ylabel(mem_id, fontsize=8)\n",
    "\n",
    "        data_agg = data_slice.mean(dim='time')\n",
    "        pcm2 = axs[index, 2].imshow(data_agg, origin='lower')\n",
    "        axs[index, 2].set_ylabel(mem_id, fontsize=8)\n",
    "\n",
    "        data_agg = data_slice.std(dim='time')\n",
    "        pcm3 = axs[index, 3].imshow(data_agg, origin='lower')\n",
    "        axs[index, 3].set_ylabel(mem_id, fontsize=8)\n",
    "       \n",
    "    \n",
    "    axs[0, 0].set_title(f'min({var})', fontsize=15)\n",
    "    axs[0, 1].set_title(f'max({var})', fontsize=15)\n",
    "    axs[0, 2].set_title(f'mean({var})', fontsize=15)\n",
    "    axs[0, 3].set_title(f'std({var})', fontsize=15)\n",
    "    \n",
    "    plt.colorbar(pcm0, ax = axs[:, 0], location='bottom', shrink=0.7)\n",
    "    plt.colorbar(pcm1, ax = axs[:, 1], location='bottom', shrink=0.7)\n",
    "    plt.colorbar(pcm2, ax = axs[:, 2], location='bottom', shrink=0.7)\n",
    "    plt.colorbar(pcm3, ax = axs[:, 3], location='bottom', shrink=0.7)\n",
    "\n",
    "    plt.suptitle(store_name, fontsize=20)\n",
    "    plt.savefig(f'{store_name}_maps.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-lens-conversion]",
   "language": "python",
   "name": "conda-env-miniconda3-lens-conversion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
